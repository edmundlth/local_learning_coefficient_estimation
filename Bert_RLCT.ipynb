{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1vZfEbcKH_rfuw83kSjhThI2J7Jm-yJpk",
      "authorship_tag": "ABX9TyMJgeebnI0z208zM+n1gqR4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edmundlth/local_learning_coefficient_estimation/blob/main/Bert_RLCT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYJ_6ajcaue1",
        "outputId": "62ce3b6e-e7b7-42a9-c4be-0a8e1f9b42f5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "!pip install transformers datasets --quiet\n",
        "import transformers\n",
        "from transformers import AutoModel, BertForSequenceClassification, AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "import pandas as pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O04xjbzpGnVQ",
        "outputId": "05c722dc-6c1e-4c0e-a9eb-46027bbcb84f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/7.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/7.2 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m132.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m116.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install engineering_notation\n",
        "from engineering_notation import EngNumber"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gr4Su1xr-fX0",
        "outputId": "5896b77b-ce48-49ab-f73a-5bf177f8c0ac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting engineering_notation\n",
            "  Downloading engineering_notation-0.8.0-py3-none-any.whl (6.6 kB)\n",
            "Installing collected packages: engineering_notation\n",
            "Successfully installed engineering_notation-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import decimal\n",
        "import torch\n",
        "from copy import deepcopy\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "class MNISTExperiment(object):\n",
        "    def __init__(\n",
        "        self,\n",
        "        net,\n",
        "        trainloader,\n",
        "        testloader,\n",
        "        optimizer,\n",
        "        device,\n",
        "        sgld_num_chains=4,\n",
        "        sgld_num_iter=100,\n",
        "        sgld_gamma=None,\n",
        "        sgld_noise_std=1e-5,\n",
        "    ):\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.testloader = testloader\n",
        "        self.optimizer = optimizer\n",
        "        self.device = device\n",
        "\n",
        "        self.sgld_num_chains = sgld_num_chains\n",
        "        self.sgld_num_iter = sgld_num_iter\n",
        "        self.sgld_gamma = sgld_gamma\n",
        "        self.sgld_noise_std = sgld_noise_std\n",
        "\n",
        "        self.batch_size = trainloader.batch_size\n",
        "        self.total_train = len(self.trainloader.dataset)\n",
        "\n",
        "        self.trainloader_iter = iter(self.trainloader)\n",
        "\n",
        "        self.records = {\n",
        "            \"lfe\": [],\n",
        "            \"energy\": [],\n",
        "            \"hatlambda\": [],\n",
        "            \"test_error\": [],\n",
        "            \"train_error\": []\n",
        "        }\n",
        "\n",
        "    def eval(self, dataloader):\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data in dataloader:\n",
        "                inputs, labels = data[0].to(self.device), data[1].to(self.device)\n",
        "                outputs = self.net(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        return correct / total\n",
        "\n",
        "    def _generate_next_training_batch(self):\n",
        "        try:\n",
        "            data = next(self.trainloader_iter)\n",
        "        except StopIteration:\n",
        "            self.trainloader_iter = iter(self.trainloader)\n",
        "            data = next(self.trainloader_iter)\n",
        "        inputs, labels = data[0].to(self.device), data[1].to(self.device)\n",
        "        return inputs, labels\n",
        "\n",
        "    def closure(self):\n",
        "        inputs, labels = self._generate_next_training_batch()\n",
        "        self.optimizer.zero_grad()\n",
        "        outputs = self.net(inputs, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        return loss, inputs, labels\n",
        "\n",
        "    def compute_energy(self):\n",
        "        # this is nL_n,k, sum of the losses at w^* found so far\n",
        "        energies = []\n",
        "        with torch.no_grad():\n",
        "            for data in self.trainloader:\n",
        "                inputs, labels = data[0].to(self.device), data[1].to(self.device)\n",
        "                outputs = self.net(inputs, labels=labels)\n",
        "                loss = outputs.loss\n",
        "                energies.append(loss.item() * self.batch_size)\n",
        "        return sum(energies)\n",
        "\n",
        "    def compute_local_free_energy(\n",
        "        self, num_iter=100, num_chains=1, gamma=None, epsilon=1e-5, verbose=True\n",
        "    ):\n",
        "        model_copy = deepcopy(self.net)\n",
        "        gamma_dict = {}\n",
        "        if gamma is None:\n",
        "            with torch.no_grad():\n",
        "                for name, param in model_copy.named_parameters():\n",
        "                    gamma_val = 100.0 / torch.linalg.norm(param)\n",
        "                    gamma_dict[name] = gamma_val\n",
        "\n",
        "\n",
        "        chain_Lms = []\n",
        "        for chain in range(num_chains):\n",
        "            model_copy = deepcopy(self.net)\n",
        "            og_params = deepcopy(dict(model_copy.named_parameters()))\n",
        "            Lms = []\n",
        "            for _ in range(num_iter):\n",
        "                with torch.enable_grad():\n",
        "                    # call a minibatch loss backward\n",
        "                    # so that we have gradient of average minibatch loss with respect to w'\n",
        "                    inputs, labels = self._generate_next_training_batch()\n",
        "                    outputs = model_copy(inputs, labels=labels)\n",
        "                    loss = outputs.loss\n",
        "                    loss.backward()\n",
        "                for name, w in model_copy.named_parameters():\n",
        "                    w_og = og_params[name]\n",
        "                    dw = -w.grad.data / np.log(self.total_train) * self.total_train\n",
        "                    if gamma is None:\n",
        "                        prior_weight = gamma_dict[name]\n",
        "                    else:\n",
        "                        prior_weight = gamma\n",
        "                    dw.add_(w.data - w_og.data, alpha=-prior_weight)\n",
        "                    w.data.add_(dw, alpha=epsilon / 2)\n",
        "                    gaussian_noise = torch.empty_like(w)\n",
        "                    gaussian_noise.normal_()\n",
        "                    w.data.add_(gaussian_noise, alpha=np.sqrt(epsilon))\n",
        "                    w.grad.zero_()\n",
        "                Lms.append(loss.item())\n",
        "            chain_Lms.append(Lms)\n",
        "            if verbose:\n",
        "                print(f\"Chain {chain + 1}: L_m = {np.mean(Lms)}\")\n",
        "\n",
        "        chain_Lms = np.array(chain_Lms)\n",
        "        local_free_energy = self.total_train * np.mean(chain_Lms)\n",
        "        if verbose:\n",
        "            chain_std = np.std(self.total_train * np.mean(chain_Lms, axis=1))\n",
        "            print(\n",
        "                f\"LFE: {EngNumber(local_free_energy)} (std: {EngNumber(chain_std)}, n_chain={num_chains})\"\n",
        "            )\n",
        "        return local_free_energy, chain_std\n",
        "\n",
        "    def _record_epoch(self):\n",
        "        local_free_energy, energy, hatlambda = self.compute_fenergy_energy_rlct()\n",
        "        self.records[\"lfe\"].append(local_free_energy)\n",
        "        self.records[\"energy\"].append(energy)\n",
        "        self.records[\"hatlambda\"].append(hatlambda)\n",
        "        test_err = 1 - self.eval(self.testloader)\n",
        "        train_err = 1 - self.eval(self.trainloader)\n",
        "\n",
        "        self.records[\"test_error\"].append(test_err)\n",
        "        self.records[\"train_error\"].append(train_err)\n",
        "        epoch = len(self.records[\"test_error\"])\n",
        "        print(\n",
        "            f\"Epoch: {epoch} \"\n",
        "            f\"energy: {energy:.4f} \"\n",
        "            f\"hatlambda: {hatlambda:.4f} \"\n",
        "            f\"test error: {test_err:.4f} \"\n",
        "            f\"train error: {train_err:.4f} \"\n",
        "        )\n",
        "        return\n",
        "\n",
        "    def compute_fenergy_energy_rlct(self):\n",
        "        energy = self.compute_energy()\n",
        "        local_free_energy, local_free_energy_std = self.compute_local_free_energy(\n",
        "            self.sgld_num_iter,\n",
        "            self.sgld_num_chains,\n",
        "            self.sgld_gamma,\n",
        "            self.sgld_noise_std,\n",
        "        )\n",
        "        lfe_standard_error = local_free_energy_std/(self.sgld_num_chains)**0.5\n",
        "\n",
        "        local_free_energy_lower_bound = local_free_energy - lfe_standard_error*2\n",
        "        local_free_energy_upper_bound = local_free_energy + lfe_standard_error*2\n",
        "\n",
        "        hatlambda = (local_free_energy - energy) / np.log(self.total_train)\n",
        "        hatlambda_lower = (local_free_energy_lower_bound - energy) / np.log(self.total_train)\n",
        "        hatlambda_upper = (local_free_energy_upper_bound - energy) / np.log(self.total_train)\n",
        "        return local_free_energy, energy, hatlambda, hatlambda_lower, hatlambda_upper\n",
        "\n",
        "    def run_entropy_sgd(self, esgd_L, num_epoch):\n",
        "        print(\"Running Entropy-SGD optimizer\")\n",
        "        # errors, lfes, energies, lmbdas = [], [], [], []\n",
        "\n",
        "        for epoch in range(num_epoch):  # loop over the dataset multiple times\n",
        "            start_time = time.time()\n",
        "            for _ in range(len(self.trainloader) // esgd_L):\n",
        "                # len(self.trainloader) is the number of minibatches,\n",
        "                # division by L is to make the same number of passes as plain SGD below\n",
        "                self.optimizer.step(self.closure)\n",
        "            self._record_epoch()\n",
        "            print(f\"Finished epoch {epoch + 1} / {num_epoch}, time taken: {time.time() - start_time:.3f}\")\n",
        "        return self.records\n",
        "\n",
        "    def run_sgd(self, num_epoch):\n",
        "        print(\"Running SGD optimizer\")\n",
        "        # SGD should be run L times longer to be fair comparison with entropy-SGD\n",
        "        # loop over the dataset multiple times\n",
        "        for epoch in range(num_epoch):\n",
        "            start_time = time.time()\n",
        "            for data in self.trainloader:\n",
        "                # get the inputs; data is a list of [inputs, labels]\n",
        "                inputs, labels = data[0].to(self.device), data[1].to(self.device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                # forward + backward + optimize\n",
        "                outputs = self.net(inputs, labels=labels)\n",
        "                loss = outputs.loss\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "            self._record_epoch()\n",
        "            print(f\"Finished epoch {epoch + 1} / {num_epoch}, time taken: {time.time() - start_time:.3f}\")\n",
        "        return self.records\n"
      ],
      "metadata": {
        "id": "UN6FUuLadjlh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5F5zuvk4D4ot"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Assuming you have your train data and labels as PyTorch tensors.\n",
        "# train_data and train_labels should be of type torch.Tensor\n",
        "# If they are numpy arrays, you can convert them to torch tensors using torch.from_numpy() function\n",
        "\n",
        "# loading training data\n",
        "train_data = torch.load(\"drive/MyDrive/bert_slt_rlct/mnli_training_data_subset.pth\")\n",
        "train_labels = torch.load(\"drive/MyDrive/bert_slt_rlct/mnli_training_labels_subset.pth\")\n",
        "\n",
        "train_dataset = TensorDataset(train_data, train_labels)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# loading test data\n",
        "test_data = torch.load(\"drive/MyDrive/bert_slt_rlct/mnli_testing_data_subset.pth\")\n",
        "test_labels = torch.load(\"drive/MyDrive/bert_slt_rlct/mnli_testing_labels_subset.pth\")\n",
        "\n",
        "test_dataset = TensorDataset(train_data, train_labels)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Models\n",
        "models = list()\n",
        "for i in range(1, 6):\n",
        "  models.append(torch.load(f\"drive/MyDrive/bert_slt_rlct/non_overfit_mnli_small_bert_{i}.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_rlct_low = list()\n",
        "model_rlct_high = list()\n",
        "model_rlct_mid = list()\n",
        "for model in models:\n",
        "  optimizer = transformers.optimization.AdamW(model.parameters(), lr = 2e-3, weight_decay = 0)\n",
        "  device = \"cuda:0\"\n",
        "  net = MNISTExperiment(model,\n",
        "                        train_dataloader,\n",
        "                        test_dataloader,\n",
        "                        optimizer,\n",
        "                        device,\n",
        "                        sgld_num_chains = 200,\n",
        "                        sgld_num_iter = 5,\n",
        "                        sgld_noise_std=1e-5,\n",
        "                        )\n",
        "\n",
        "  fenergy, energy, rlct, lower, upper = net.compute_fenergy_energy_rlct()\n",
        "  print()\n",
        "  print(\"---\")\n",
        "  print(f\"Data for model {i}:\")\n",
        "  print(f\"95% lambdahat confidence interval: {EngNumber(lower)}-{EngNumber(upper)}\")\n",
        "  print(f\"Mean lambdahat: {EngNumber(rlct)}\")\n",
        "  print(f\"Free energy: {EngNumber(fenergy)}\")\n",
        "  print(f\"Energy: {EngNumber(energy)}\")\n",
        "  print(\"---\")\n",
        "  print()\n",
        "  model_rlct_low.append(lower)\n",
        "  model_rlct_high.append(upper)\n",
        "  model_rlct_mid.append(rlct)"
      ],
      "metadata": {
        "id": "cwzpsr_0F9mC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df983aea-9ccd-45f3-9b09-464cc6243c73"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chain 1: L_m = 1.009008002281189\n",
            "Chain 2: L_m = 1.269812786579132\n",
            "Chain 3: L_m = 0.3481311917304993\n",
            "Chain 4: L_m = 1.4019922733306884\n",
            "Chain 5: L_m = 1.0784075856208801\n",
            "Chain 6: L_m = 0.6516258955001831\n",
            "Chain 7: L_m = 1.0560375094413756\n",
            "Chain 8: L_m = 0.2801062077283859\n",
            "Chain 9: L_m = 0.8994292616844177\n",
            "Chain 10: L_m = 0.2767772823572159\n",
            "Chain 11: L_m = 0.32988073527812956\n",
            "Chain 12: L_m = 0.5943172633647918\n",
            "Chain 13: L_m = 0.3725042551755905\n",
            "Chain 14: L_m = 0.3763133525848389\n",
            "Chain 15: L_m = 0.6130687952041626\n",
            "Chain 16: L_m = 0.3781674563884735\n",
            "Chain 17: L_m = 1.8827911168336868\n",
            "Chain 18: L_m = 0.3250880569219589\n",
            "Chain 19: L_m = 0.8363217681646347\n",
            "Chain 20: L_m = 0.5841808140277862\n",
            "Chain 21: L_m = 0.46314270198345187\n",
            "Chain 22: L_m = 0.2825740724802017\n",
            "Chain 23: L_m = 0.9193332076072693\n",
            "Chain 24: L_m = 0.3925476402044296\n",
            "Chain 25: L_m = 0.5183261096477508\n",
            "Chain 26: L_m = 0.3125071346759796\n",
            "Chain 27: L_m = 0.2931938409805298\n",
            "Chain 28: L_m = 0.25702306926250457\n",
            "Chain 29: L_m = 0.5200364738702774\n",
            "Chain 30: L_m = 0.34598017334938047\n",
            "Chain 31: L_m = 0.3931456744670868\n",
            "Chain 32: L_m = 0.21679362505674363\n",
            "Chain 33: L_m = 1.232639980316162\n",
            "Chain 34: L_m = 1.147852998971939\n",
            "Chain 35: L_m = 0.6863747298717499\n",
            "Chain 36: L_m = 0.4978517353534698\n",
            "Chain 37: L_m = 0.7070655405521393\n",
            "Chain 38: L_m = 0.5463960826396942\n",
            "Chain 39: L_m = 0.583125901222229\n",
            "Chain 40: L_m = 0.3528808891773224\n",
            "Chain 41: L_m = 1.0566746473312378\n",
            "Chain 42: L_m = 0.6419862002134323\n",
            "Chain 43: L_m = 1.0183225691318512\n",
            "Chain 44: L_m = 0.2419111430644989\n",
            "Chain 45: L_m = 0.9995545983314514\n",
            "Chain 46: L_m = 0.37687196433544157\n",
            "Chain 47: L_m = 0.5105639040470124\n",
            "Chain 48: L_m = 0.36552888453006743\n",
            "Chain 49: L_m = 0.43918873369693756\n",
            "Chain 50: L_m = 0.6910738080739975\n",
            "Chain 51: L_m = 0.35937579870224\n",
            "Chain 52: L_m = 0.9344951331615448\n",
            "Chain 53: L_m = 0.21744132190942764\n",
            "Chain 54: L_m = 0.513851922750473\n",
            "Chain 55: L_m = 1.0353419661521912\n",
            "Chain 56: L_m = 0.2819288581609726\n",
            "Chain 57: L_m = 0.2646320730447769\n",
            "Chain 58: L_m = 0.8320851266384125\n",
            "Chain 59: L_m = 0.3369734317064285\n",
            "Chain 60: L_m = 0.5025991976261139\n",
            "Chain 61: L_m = 0.7265816152095794\n",
            "Chain 62: L_m = 0.5553436011075974\n",
            "Chain 63: L_m = 0.6908853620290756\n",
            "Chain 64: L_m = 0.558815997838974\n",
            "Chain 65: L_m = 1.4520462661981584\n",
            "Chain 66: L_m = 0.6641732424497604\n",
            "Chain 67: L_m = 1.0671529531478883\n",
            "Chain 68: L_m = 0.32841612696647643\n",
            "Chain 69: L_m = 1.3243330597877503\n",
            "Chain 70: L_m = 0.9581163585186004\n",
            "Chain 71: L_m = 1.1252523183822631\n",
            "Chain 72: L_m = 0.6230831176042557\n",
            "Chain 73: L_m = 0.998375517129898\n",
            "Chain 74: L_m = 0.2743525207042694\n",
            "Chain 75: L_m = 0.7552524268627167\n",
            "Chain 76: L_m = 1.365589714050293\n",
            "Chain 77: L_m = 0.9718770027160645\n",
            "Chain 78: L_m = 0.4423088997602463\n",
            "Chain 79: L_m = 0.630041241645813\n",
            "Chain 80: L_m = 0.28902225494384765\n",
            "Chain 81: L_m = 0.5997859328985214\n",
            "Chain 82: L_m = 0.37933981120586396\n",
            "Chain 83: L_m = 0.5252059787511826\n",
            "Chain 84: L_m = 0.5756487220525741\n",
            "Chain 85: L_m = 0.3424528732895851\n",
            "Chain 86: L_m = 1.4117497503757477\n",
            "Chain 87: L_m = 0.8954340696334839\n",
            "Chain 88: L_m = 1.5495830327272415\n",
            "Chain 89: L_m = 0.7538490295410156\n",
            "Chain 90: L_m = 0.7250054180622101\n",
            "Chain 91: L_m = 0.7573597013950348\n",
            "Chain 92: L_m = 0.43711849451065066\n",
            "Chain 93: L_m = 0.5711527109146118\n",
            "Chain 94: L_m = 0.21088442206382751\n",
            "Chain 95: L_m = 1.0055850327014924\n",
            "Chain 96: L_m = 0.8209835469722748\n",
            "Chain 97: L_m = 0.8551204442977905\n",
            "Chain 98: L_m = 0.5359898924827575\n",
            "Chain 99: L_m = 0.3113176912069321\n",
            "Chain 100: L_m = 0.7201538711786271\n",
            "Chain 101: L_m = 0.4218311220407486\n",
            "Chain 102: L_m = 0.48630360662937167\n",
            "Chain 103: L_m = 1.3777053773403167\n",
            "Chain 104: L_m = 0.2901460528373718\n",
            "Chain 105: L_m = 0.5613877892494201\n",
            "Chain 106: L_m = 0.35163386464118956\n",
            "Chain 107: L_m = 0.31116441190242766\n",
            "Chain 108: L_m = 1.3290312170982361\n",
            "Chain 109: L_m = 0.6050861328840256\n",
            "Chain 110: L_m = 1.438790601491928\n",
            "Chain 111: L_m = 1.0749106764793397\n",
            "Chain 112: L_m = 0.5659745633602142\n",
            "Chain 113: L_m = 0.42057124674320223\n",
            "Chain 114: L_m = 0.6199553906917572\n",
            "Chain 115: L_m = 0.5191283643245697\n",
            "Chain 116: L_m = 1.09652319252491\n",
            "Chain 117: L_m = 0.279136922955513\n",
            "Chain 118: L_m = 0.4284764021635056\n",
            "Chain 119: L_m = 0.7507441401481628\n",
            "Chain 120: L_m = 0.7717096209526062\n",
            "Chain 121: L_m = 1.208501046895981\n",
            "Chain 122: L_m = 0.6659305393695831\n",
            "Chain 123: L_m = 0.33670233339071276\n",
            "Chain 124: L_m = 1.341104018688202\n",
            "Chain 125: L_m = 0.3103525549173355\n",
            "Chain 126: L_m = 0.19645503759384156\n",
            "Chain 127: L_m = 0.5182497948408127\n",
            "Chain 128: L_m = 0.7367961466312408\n",
            "Chain 129: L_m = 0.6569381445646286\n",
            "Chain 130: L_m = 0.7067019492387772\n",
            "Chain 131: L_m = 1.3161269158124924\n",
            "Chain 132: L_m = 0.5532358050346374\n",
            "Chain 133: L_m = 0.6646907567977905\n",
            "Chain 134: L_m = 0.2951370030641556\n",
            "Chain 135: L_m = 1.7127606749534607\n",
            "Chain 136: L_m = 0.2516065567731857\n",
            "Chain 137: L_m = 0.6521691113710404\n",
            "Chain 138: L_m = 0.4975982427597046\n",
            "Chain 139: L_m = 0.7472316205501557\n",
            "Chain 140: L_m = 0.3209618151187897\n",
            "Chain 141: L_m = 1.5412117660045623\n",
            "Chain 142: L_m = 0.34810838401317595\n",
            "Chain 143: L_m = 0.8418146789073944\n",
            "Chain 144: L_m = 0.28019029796123507\n",
            "Chain 145: L_m = 0.48836885690689086\n",
            "Chain 146: L_m = 0.9766135066747665\n",
            "Chain 147: L_m = 0.9217443943023682\n",
            "Chain 148: L_m = 0.32961157262325286\n",
            "Chain 149: L_m = 0.8134774744510651\n",
            "Chain 150: L_m = 0.6964549392461776\n",
            "Chain 151: L_m = 1.3045335054397582\n",
            "Chain 152: L_m = 0.9831949353218079\n",
            "Chain 153: L_m = 0.3620882421731949\n",
            "Chain 154: L_m = 1.814067190885544\n",
            "Chain 155: L_m = 0.5969686448574066\n",
            "Chain 156: L_m = 0.3020441472530365\n",
            "Chain 157: L_m = 0.2827014774084091\n",
            "Chain 158: L_m = 0.22224780917167664\n",
            "Chain 159: L_m = 0.23980090916156768\n",
            "Chain 160: L_m = 0.3458769738674164\n",
            "Chain 161: L_m = 0.3288084864616394\n",
            "Chain 162: L_m = 0.375635039806366\n",
            "Chain 163: L_m = 0.29566940665245056\n",
            "Chain 164: L_m = 0.9731430143117905\n",
            "Chain 165: L_m = 1.3539122134447097\n",
            "Chain 166: L_m = 1.28620126247406\n",
            "Chain 167: L_m = 1.0749556183815003\n",
            "Chain 168: L_m = 0.4492897242307663\n",
            "Chain 169: L_m = 0.877337247133255\n",
            "Chain 170: L_m = 0.45880080461502076\n",
            "Chain 171: L_m = 1.7140161573886872\n",
            "Chain 172: L_m = 0.5024576753377914\n",
            "Chain 173: L_m = 0.781488561630249\n",
            "Chain 174: L_m = 0.4705828666687012\n",
            "Chain 175: L_m = 0.4763871103525162\n",
            "Chain 176: L_m = 0.4654573440551758\n",
            "Chain 177: L_m = 0.3723540484905243\n",
            "Chain 178: L_m = 0.8853387802839279\n",
            "Chain 179: L_m = 0.34595719575881956\n",
            "Chain 180: L_m = 0.5502625495195389\n",
            "Chain 181: L_m = 1.0853944838047027\n",
            "Chain 182: L_m = 1.0063829571008682\n",
            "Chain 183: L_m = 0.3047040641307831\n",
            "Chain 184: L_m = 1.3004046469926833\n",
            "Chain 185: L_m = 0.28235298693180083\n",
            "Chain 186: L_m = 1.14874324798584\n",
            "Chain 187: L_m = 0.7770578682422637\n",
            "Chain 188: L_m = 0.7228912085294723\n",
            "Chain 189: L_m = 0.3001804918050766\n",
            "Chain 190: L_m = 1.0282103687524795\n",
            "Chain 191: L_m = 0.5008626759052277\n",
            "Chain 192: L_m = 0.3468037635087967\n",
            "Chain 193: L_m = 0.5468997716903686\n",
            "Chain 194: L_m = 0.32674760222434995\n",
            "Chain 195: L_m = 0.8157752454280853\n",
            "Chain 196: L_m = 0.3394510507583618\n",
            "Chain 197: L_m = 1.1542557686567307\n",
            "Chain 198: L_m = 0.2928752213716507\n",
            "Chain 199: L_m = 0.448162579536438\n",
            "Chain 200: L_m = 0.5166366994380951\n",
            "LFE: 60.75k (std: 33.55k, n_chain=200)\n",
            "\n",
            "---\n",
            "Data for model 4:\n",
            "95% lambdahat confidence interval: 2.76k-3.59k\n",
            "Mean lambdahat: 3.17k\n",
            "Free energy: 60.75k\n",
            "Energy: 24.54k\n",
            "---\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chain 1: L_m = 0.8862992465496063\n",
            "Chain 2: L_m = 0.4826162546873093\n",
            "Chain 3: L_m = 0.5302879333496093\n",
            "Chain 4: L_m = 0.9021453320980072\n",
            "Chain 5: L_m = 1.0589762806892395\n",
            "Chain 6: L_m = 0.4235114872455597\n",
            "Chain 7: L_m = 4.8776222437620165\n",
            "Chain 8: L_m = 1.6952634632587433\n",
            "Chain 9: L_m = 2.981574684381485\n",
            "Chain 10: L_m = 1.449630504846573\n",
            "Chain 11: L_m = 1.8420335054397583\n",
            "Chain 12: L_m = 2.05920824110508\n",
            "Chain 13: L_m = 4.852935808897018\n",
            "Chain 14: L_m = 2.967543566226959\n",
            "Chain 15: L_m = 4.030357921123505\n",
            "Chain 16: L_m = 2.2906035602092745\n",
            "Chain 17: L_m = 0.47008504569530485\n",
            "Chain 18: L_m = 1.2645684957504273\n",
            "Chain 19: L_m = 0.7836362779140472\n",
            "Chain 20: L_m = 3.8778687179088593\n",
            "Chain 21: L_m = 0.6816185861825943\n",
            "Chain 22: L_m = 1.6130731284618378\n",
            "Chain 23: L_m = 3.7531589567661285\n",
            "Chain 24: L_m = 2.3230449497699737\n",
            "Chain 25: L_m = 3.7553028374910356\n",
            "Chain 26: L_m = 3.398603343963623\n",
            "Chain 27: L_m = 4.950607270002365\n",
            "Chain 28: L_m = 3.4939595639705656\n",
            "Chain 29: L_m = 1.9512363374233246\n",
            "Chain 30: L_m = 5.5630716443061825\n",
            "Chain 31: L_m = 1.3965197414159776\n",
            "Chain 32: L_m = 4.598817449808121\n",
            "Chain 33: L_m = 0.7346053570508957\n",
            "Chain 34: L_m = 5.969200152158737\n",
            "Chain 35: L_m = 2.8993895411491395\n",
            "Chain 36: L_m = 2.20162633061409\n",
            "Chain 37: L_m = 0.9466974079608917\n",
            "Chain 38: L_m = 2.9509680807590484\n",
            "Chain 39: L_m = 3.2231138229370115\n",
            "Chain 40: L_m = 3.8588798195123672\n",
            "Chain 41: L_m = 1.8066705763339996\n",
            "Chain 42: L_m = 2.033035856485367\n",
            "Chain 43: L_m = 1.1537512987852097\n",
            "Chain 44: L_m = 2.6208541631698608\n",
            "Chain 45: L_m = 2.310896176099777\n",
            "Chain 46: L_m = 2.7958659291267396\n",
            "Chain 47: L_m = 3.5599429965019227\n",
            "Chain 48: L_m = 2.483007949590683\n",
            "Chain 49: L_m = 3.0724470794200895\n",
            "Chain 50: L_m = 4.634059518575668\n",
            "Chain 51: L_m = 0.9274823486804962\n",
            "Chain 52: L_m = 2.522506260871887\n",
            "Chain 53: L_m = 5.530556535720825\n",
            "Chain 54: L_m = 3.5516469091176988\n",
            "Chain 55: L_m = 2.101273259520531\n",
            "Chain 56: L_m = 1.7925446510314942\n",
            "Chain 57: L_m = 1.2314752221107483\n",
            "Chain 58: L_m = 2.062453252077103\n",
            "Chain 59: L_m = 2.6638588190078734\n",
            "Chain 60: L_m = 2.5830703377723694\n",
            "Chain 61: L_m = 1.209362083673477\n",
            "Chain 62: L_m = 4.0170057117938995\n",
            "Chain 63: L_m = 0.45254250168800353\n",
            "Chain 64: L_m = 2.123800057172775\n",
            "Chain 65: L_m = 4.577971363067627\n",
            "Chain 66: L_m = 4.45176197886467\n",
            "Chain 67: L_m = 2.1094388127326966\n",
            "Chain 68: L_m = 4.220200312137604\n",
            "Chain 69: L_m = 0.296394108235836\n",
            "Chain 70: L_m = 1.9890660881996154\n",
            "Chain 71: L_m = 2.4407843858003617\n",
            "Chain 72: L_m = 2.788998860120773\n",
            "Chain 73: L_m = 7.622386312484741\n",
            "Chain 74: L_m = 0.4040806382894516\n",
            "Chain 75: L_m = 1.6334359675645829\n",
            "Chain 76: L_m = 2.099199283123016\n",
            "Chain 77: L_m = 0.3447025567293167\n",
            "Chain 78: L_m = 1.3628721088171005\n",
            "Chain 79: L_m = 2.277184420824051\n",
            "Chain 80: L_m = 1.306921273469925\n",
            "Chain 81: L_m = 6.698435586690903\n",
            "Chain 82: L_m = 3.6292346477508546\n",
            "Chain 83: L_m = 0.38359190821647643\n",
            "Chain 84: L_m = 5.1497851490974424\n",
            "Chain 85: L_m = 6.574666237831115\n",
            "Chain 86: L_m = 0.36127073764801027\n",
            "Chain 87: L_m = 1.2077878057956695\n",
            "Chain 88: L_m = 0.3536034613847733\n",
            "Chain 89: L_m = 3.072452414035797\n",
            "Chain 90: L_m = 0.7514322161674499\n",
            "Chain 91: L_m = 4.9564886957407\n",
            "Chain 92: L_m = 6.784626942873001\n",
            "Chain 93: L_m = 2.2569672644138334\n",
            "Chain 94: L_m = 5.093883633613586\n",
            "Chain 95: L_m = 2.690756094455719\n",
            "Chain 96: L_m = 0.34408727288246155\n",
            "Chain 97: L_m = 3.5868452072143553\n",
            "Chain 98: L_m = 3.1151619136333464\n",
            "Chain 99: L_m = 0.731163477897644\n",
            "Chain 100: L_m = 0.2751831978559494\n",
            "Chain 101: L_m = 0.3914290428161621\n",
            "Chain 102: L_m = 2.914993605017662\n",
            "Chain 103: L_m = 1.170566475391388\n",
            "Chain 104: L_m = 0.8402328461408615\n",
            "Chain 105: L_m = 2.093961650133133\n",
            "Chain 106: L_m = 2.2406872689723967\n",
            "Chain 107: L_m = 3.973891445994377\n",
            "Chain 108: L_m = 2.044634607434273\n",
            "Chain 109: L_m = 2.0305808544158936\n",
            "Chain 110: L_m = 0.416530704498291\n",
            "Chain 111: L_m = 0.6061040818691253\n",
            "Chain 112: L_m = 0.5015990018844605\n",
            "Chain 113: L_m = 1.4673160195350647\n",
            "Chain 114: L_m = 0.5779258012771606\n",
            "Chain 115: L_m = 4.039402723312378\n",
            "Chain 116: L_m = 0.3838605523109436\n",
            "Chain 117: L_m = 6.216551077365875\n",
            "Chain 118: L_m = 1.385920250415802\n",
            "Chain 119: L_m = 1.0771090149879456\n",
            "Chain 120: L_m = 0.3435076385736465\n",
            "Chain 121: L_m = 0.3498111754655838\n",
            "Chain 122: L_m = 1.1631076067686081\n",
            "Chain 123: L_m = 1.5794298261404038\n",
            "Chain 124: L_m = 0.9001173436641693\n",
            "Chain 125: L_m = 3.5497488409280775\n",
            "Chain 126: L_m = 0.6583318412303925\n",
            "Chain 127: L_m = 0.3597770929336548\n",
            "Chain 128: L_m = 0.9110365301370621\n",
            "Chain 129: L_m = 6.593289119005203\n",
            "Chain 130: L_m = 0.8457477509975433\n",
            "Chain 131: L_m = 0.6971400797367096\n",
            "Chain 132: L_m = 3.5991068303585054\n",
            "Chain 133: L_m = 3.523754584789276\n",
            "Chain 134: L_m = 3.196440500020981\n",
            "Chain 135: L_m = 1.4348193734884263\n",
            "Chain 136: L_m = 3.3058036386966707\n",
            "Chain 137: L_m = 2.5784646391868593\n",
            "Chain 138: L_m = 2.1956615418195726\n",
            "Chain 139: L_m = 1.899530726671219\n",
            "Chain 140: L_m = 1.1254506528377533\n",
            "Chain 141: L_m = 2.1297230571508408\n",
            "Chain 142: L_m = 1.8899376749992371\n",
            "Chain 143: L_m = 4.768200001120567\n",
            "Chain 144: L_m = 0.9561954036355018\n",
            "Chain 145: L_m = 2.511619120836258\n",
            "Chain 146: L_m = 2.2038106501102446\n",
            "Chain 147: L_m = 9.196715122461319\n",
            "Chain 148: L_m = 0.8522391229867935\n",
            "Chain 149: L_m = 2.2672709107398985\n",
            "Chain 150: L_m = 0.8066275179386139\n",
            "Chain 151: L_m = 1.2382894724607467\n",
            "Chain 152: L_m = 2.582628497481346\n",
            "Chain 153: L_m = 4.036461061239242\n",
            "Chain 154: L_m = 0.7366320371627808\n",
            "Chain 155: L_m = 4.521356183290481\n",
            "Chain 156: L_m = 0.7029431611299515\n",
            "Chain 157: L_m = 3.3925454884767534\n",
            "Chain 158: L_m = 1.974337100982666\n",
            "Chain 159: L_m = 3.316679871082306\n",
            "Chain 160: L_m = 1.7381959170103074\n",
            "Chain 161: L_m = 1.9442235827445984\n",
            "Chain 162: L_m = 5.0248853206634525\n",
            "Chain 163: L_m = 2.312560909986496\n",
            "Chain 164: L_m = 0.4507317304611206\n",
            "Chain 165: L_m = 2.857026207447052\n",
            "Chain 166: L_m = 0.5393169343471527\n",
            "Chain 167: L_m = 1.4095965057611466\n",
            "Chain 168: L_m = 1.7541089534759522\n",
            "Chain 169: L_m = 2.305412086844444\n",
            "Chain 170: L_m = 1.689207249879837\n",
            "Chain 171: L_m = 0.8956787347793579\n",
            "Chain 172: L_m = 1.47185577750206\n",
            "Chain 173: L_m = 0.721508777141571\n",
            "Chain 174: L_m = 0.5782942742109298\n",
            "Chain 175: L_m = 2.781052178144455\n",
            "Chain 176: L_m = 4.94732152223587\n",
            "Chain 177: L_m = 2.897822839021683\n",
            "Chain 178: L_m = 0.23068950176239014\n",
            "Chain 179: L_m = 3.259027662873268\n",
            "Chain 180: L_m = 2.337749791145325\n",
            "Chain 181: L_m = 4.102807813882828\n",
            "Chain 182: L_m = 4.462833958864212\n",
            "Chain 183: L_m = 1.6038742125034333\n",
            "Chain 184: L_m = 5.642926430702209\n",
            "Chain 185: L_m = 1.664464145898819\n",
            "Chain 186: L_m = 5.478788876533509\n",
            "Chain 187: L_m = 1.2063510835170745\n",
            "Chain 188: L_m = 2.8555431187152864\n",
            "Chain 189: L_m = 2.4195635706186294\n",
            "Chain 190: L_m = 0.8759692668914795\n",
            "Chain 191: L_m = 1.138314852118492\n",
            "Chain 192: L_m = 4.275566220283508\n",
            "Chain 193: L_m = 0.32328580021858216\n",
            "Chain 194: L_m = 0.8200392901897431\n",
            "Chain 195: L_m = 2.4335646659135817\n",
            "Chain 196: L_m = 3.3338449567556383\n",
            "Chain 197: L_m = 2.66270552277565\n",
            "Chain 198: L_m = 0.39236840009689333\n",
            "Chain 199: L_m = 2.7206799030303954\n",
            "Chain 200: L_m = 1.75312038064003\n",
            "LFE: 213.64k (std: 150.75k, n_chain=200)\n",
            "\n",
            "---\n",
            "Data for model 4:\n",
            "95% lambdahat confidence interval: 14.57k-18.31k\n",
            "Mean lambdahat: 16.44k\n",
            "Free energy: 213.64k\n",
            "Energy: 26.14k\n",
            "---\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chain 1: L_m = 1.0050874888896941\n",
            "Chain 2: L_m = 1.6022550642490387\n",
            "Chain 3: L_m = 2.009458029270172\n",
            "Chain 4: L_m = 0.568588238954544\n",
            "Chain 5: L_m = 0.6960787355899811\n",
            "Chain 6: L_m = 0.6445960402488708\n",
            "Chain 7: L_m = 0.9098561942577362\n",
            "Chain 8: L_m = 0.691326642036438\n",
            "Chain 9: L_m = 1.236388510465622\n",
            "Chain 10: L_m = 1.5756377935409547\n",
            "Chain 11: L_m = 1.4509209543466568\n",
            "Chain 12: L_m = 0.6778219699859619\n",
            "Chain 13: L_m = 1.5216062307357787\n",
            "Chain 14: L_m = 1.2966041147708893\n",
            "Chain 15: L_m = 0.7088881492614746\n",
            "Chain 16: L_m = 0.7702719211578369\n",
            "Chain 17: L_m = 0.7817010581493378\n",
            "Chain 18: L_m = 0.7715225100517273\n",
            "Chain 19: L_m = 2.249972552061081\n",
            "Chain 20: L_m = 0.3956453502178192\n",
            "Chain 21: L_m = 0.7386801064014434\n",
            "Chain 22: L_m = 1.9504074811935426\n",
            "Chain 23: L_m = 0.2651714369654655\n",
            "Chain 24: L_m = 0.5072966635227203\n",
            "Chain 25: L_m = 0.6755021095275879\n",
            "Chain 26: L_m = 0.7268991708755493\n",
            "Chain 27: L_m = 0.33813768029212954\n",
            "Chain 28: L_m = 0.375960373878479\n",
            "Chain 29: L_m = 0.9734169542789459\n",
            "Chain 30: L_m = 1.447191047668457\n",
            "Chain 31: L_m = 0.6499446928501129\n",
            "Chain 32: L_m = 1.1764426529407501\n",
            "Chain 33: L_m = 0.4300313055515289\n",
            "Chain 34: L_m = 0.8638691157102585\n",
            "Chain 35: L_m = 0.3499787151813507\n",
            "Chain 36: L_m = 0.64226895570755\n",
            "Chain 37: L_m = 1.405215960741043\n",
            "Chain 38: L_m = 0.6424399614334106\n",
            "Chain 39: L_m = 0.544972088932991\n",
            "Chain 40: L_m = 0.7177513897418976\n",
            "Chain 41: L_m = 2.33908126950264\n",
            "Chain 42: L_m = 0.2911573052406311\n",
            "Chain 43: L_m = 1.3370627552270888\n",
            "Chain 44: L_m = 0.84574174284935\n",
            "Chain 45: L_m = 1.1968068808317185\n",
            "Chain 46: L_m = 0.668087500333786\n",
            "Chain 47: L_m = 1.0048282265663147\n",
            "Chain 48: L_m = 1.599577534198761\n",
            "Chain 49: L_m = 0.5910743832588196\n",
            "Chain 50: L_m = 0.8632153391838073\n",
            "Chain 51: L_m = 0.5770244568586349\n",
            "Chain 52: L_m = 0.4804717540740967\n",
            "Chain 53: L_m = 1.168412485718727\n",
            "Chain 54: L_m = 1.2528303861618042\n",
            "Chain 55: L_m = 0.3752864599227905\n",
            "Chain 56: L_m = 0.5785703122615814\n",
            "Chain 57: L_m = 0.8571226835250855\n",
            "Chain 58: L_m = 0.6935287833213806\n",
            "Chain 59: L_m = 1.3764900863170624\n",
            "Chain 60: L_m = 0.6843766331672668\n",
            "Chain 61: L_m = 0.6573721647262574\n",
            "Chain 62: L_m = 0.6030711591243744\n",
            "Chain 63: L_m = 0.8463006883859634\n",
            "Chain 64: L_m = 0.9851511359214783\n",
            "Chain 65: L_m = 1.6266633540391922\n",
            "Chain 66: L_m = 0.7289371490478516\n",
            "Chain 67: L_m = 1.5254405379295348\n",
            "Chain 68: L_m = 0.8343226611614227\n",
            "Chain 69: L_m = 0.696141603589058\n",
            "Chain 70: L_m = 1.5299538373947144\n",
            "Chain 71: L_m = 1.4888158917427063\n",
            "Chain 72: L_m = 0.8584987759590149\n",
            "Chain 73: L_m = 0.3927156001329422\n",
            "Chain 74: L_m = 0.8311358243227005\n",
            "Chain 75: L_m = 0.9761775940656662\n",
            "Chain 76: L_m = 0.9250671356916428\n",
            "Chain 77: L_m = 0.46955578923225405\n",
            "Chain 78: L_m = 1.0221455454826356\n",
            "Chain 79: L_m = 0.8072444781661033\n",
            "Chain 80: L_m = 2.1152204394340517\n",
            "Chain 81: L_m = 1.8820093035697938\n",
            "Chain 82: L_m = 0.4636480867862701\n",
            "Chain 83: L_m = 1.0002418279647827\n",
            "Chain 84: L_m = 0.8236238718032837\n",
            "Chain 85: L_m = 2.2528049111366273\n",
            "Chain 86: L_m = 0.3532786577939987\n",
            "Chain 87: L_m = 0.9304144084453583\n",
            "Chain 88: L_m = 0.5558364629745484\n",
            "Chain 89: L_m = 0.6192031919956207\n",
            "Chain 90: L_m = 0.4085442066192627\n",
            "Chain 91: L_m = 0.4367992222309113\n",
            "Chain 92: L_m = 1.5545004308223724\n",
            "Chain 93: L_m = 0.30260388255119325\n",
            "Chain 94: L_m = 1.3407228708267211\n",
            "Chain 95: L_m = 1.0862585365772248\n",
            "Chain 96: L_m = 1.9823844313621521\n",
            "Chain 97: L_m = 0.28065661489963534\n",
            "Chain 98: L_m = 0.4561907470226288\n",
            "Chain 99: L_m = 0.845691841840744\n",
            "Chain 100: L_m = 1.2830440282821656\n",
            "Chain 101: L_m = 1.1944236993789672\n",
            "Chain 102: L_m = 0.39410277009010314\n",
            "Chain 103: L_m = 1.685711070895195\n",
            "Chain 104: L_m = 0.9445448458194733\n",
            "Chain 105: L_m = 1.0965877056121827\n",
            "Chain 106: L_m = 0.29551776945590974\n",
            "Chain 107: L_m = 0.2743260204792023\n",
            "Chain 108: L_m = 0.6707672476768494\n",
            "Chain 109: L_m = 0.39880931973457334\n",
            "Chain 110: L_m = 0.820451095700264\n",
            "Chain 111: L_m = 0.41481855511665344\n",
            "Chain 112: L_m = 1.2332961559295654\n",
            "Chain 113: L_m = 0.6460058063268661\n",
            "Chain 114: L_m = 0.9240111351013184\n",
            "Chain 115: L_m = 0.9596260011196136\n",
            "Chain 116: L_m = 1.453052967786789\n",
            "Chain 117: L_m = 0.4340343952178955\n",
            "Chain 118: L_m = 0.8665373504161835\n",
            "Chain 119: L_m = 1.5288057029247284\n",
            "Chain 120: L_m = 1.262826031446457\n",
            "Chain 121: L_m = 0.8283851683139801\n",
            "Chain 122: L_m = 1.5677843034267425\n",
            "Chain 123: L_m = 0.694843339920044\n",
            "Chain 124: L_m = 0.7142249584197998\n",
            "Chain 125: L_m = 0.5964700847864151\n",
            "Chain 126: L_m = 1.1103467345237732\n",
            "Chain 127: L_m = 0.9909148395061493\n",
            "Chain 128: L_m = 0.8174553751945496\n",
            "Chain 129: L_m = 0.8203973352909089\n",
            "Chain 130: L_m = 1.7833402574062347\n",
            "Chain 131: L_m = 1.0940839231014252\n",
            "Chain 132: L_m = 0.8030871510505676\n",
            "Chain 133: L_m = 0.4696382462978363\n",
            "Chain 134: L_m = 0.8329246997833252\n",
            "Chain 135: L_m = 1.329951399564743\n",
            "Chain 136: L_m = 1.1575548887252807\n",
            "Chain 137: L_m = 1.105747777223587\n",
            "Chain 138: L_m = 0.8952584385871887\n",
            "Chain 139: L_m = 1.7501043677330017\n",
            "Chain 140: L_m = 0.43177130818367004\n",
            "Chain 141: L_m = 0.27591767609119416\n",
            "Chain 142: L_m = 1.2968508780002594\n",
            "Chain 143: L_m = 0.7007464289665222\n",
            "Chain 144: L_m = 0.5096682041883469\n",
            "Chain 145: L_m = 0.9076980590820313\n",
            "Chain 146: L_m = 1.3402880549430847\n",
            "Chain 147: L_m = 0.8218369603157043\n",
            "Chain 148: L_m = 0.6531546115875244\n",
            "Chain 149: L_m = 1.3460122525691987\n",
            "Chain 150: L_m = 1.436483234167099\n",
            "Chain 151: L_m = 1.3076982378959656\n",
            "Chain 152: L_m = 1.182567059993744\n",
            "Chain 153: L_m = 1.2353065580129623\n",
            "Chain 154: L_m = 1.3990280836820603\n",
            "Chain 155: L_m = 1.1912199437618256\n",
            "Chain 156: L_m = 0.47349134683609007\n",
            "Chain 157: L_m = 1.2778353691101074\n",
            "Chain 158: L_m = 0.9232654750347138\n",
            "Chain 159: L_m = 0.8181391835212708\n",
            "Chain 160: L_m = 0.5179242879152298\n",
            "Chain 161: L_m = 1.2012496322393418\n",
            "Chain 162: L_m = 0.30573669672012327\n",
            "Chain 163: L_m = 0.6625654548406601\n",
            "Chain 164: L_m = 1.2312229990959167\n",
            "Chain 165: L_m = 1.5536331057548523\n",
            "Chain 166: L_m = 1.0182102531194688\n",
            "Chain 167: L_m = 0.2653984367847443\n",
            "Chain 168: L_m = 1.1214340537786485\n",
            "Chain 169: L_m = 0.6844389081001282\n",
            "Chain 170: L_m = 0.6868488937616348\n",
            "Chain 171: L_m = 0.38828760087490083\n",
            "Chain 172: L_m = 1.6359791994094848\n",
            "Chain 173: L_m = 0.5062437176704406\n",
            "Chain 174: L_m = 0.8257761836051941\n",
            "Chain 175: L_m = 0.5470093637704849\n",
            "Chain 176: L_m = 0.35748093873262404\n",
            "Chain 177: L_m = 0.45297654867172243\n",
            "Chain 178: L_m = 0.5286292046308517\n",
            "Chain 179: L_m = 1.8307369530200959\n",
            "Chain 180: L_m = 1.252584570646286\n",
            "Chain 181: L_m = 1.2916852593421937\n",
            "Chain 182: L_m = 0.9083834230899811\n",
            "Chain 183: L_m = 1.8039581239223481\n",
            "Chain 184: L_m = 0.2683310240507126\n",
            "Chain 185: L_m = 1.8931735098361968\n",
            "Chain 186: L_m = 0.6492472529411316\n",
            "Chain 187: L_m = 0.6229592859745026\n",
            "Chain 188: L_m = 0.6574518620967865\n",
            "Chain 189: L_m = 0.282410329580307\n",
            "Chain 190: L_m = 0.2959383189678192\n",
            "Chain 191: L_m = 1.2175910204648972\n",
            "Chain 192: L_m = 0.7111886322498322\n",
            "Chain 193: L_m = 0.6794240057468415\n",
            "Chain 194: L_m = 1.8259322226047516\n",
            "Chain 195: L_m = 1.4030959874391555\n",
            "Chain 196: L_m = 1.1600253731012344\n",
            "Chain 197: L_m = 1.5000761955976487\n",
            "Chain 198: L_m = 0.7412640988826752\n",
            "Chain 199: L_m = 0.8917308568954467\n",
            "Chain 200: L_m = 0.3844178795814514\n",
            "LFE: 84.46k (std: 41.84k, n_chain=200)\n",
            "\n",
            "---\n",
            "Data for model 4:\n",
            "95% lambdahat confidence interval: 4.55k-5.59k\n",
            "Mean lambdahat: 5.07k\n",
            "Free energy: 84.46k\n",
            "Energy: 26.65k\n",
            "---\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chain 1: L_m = 4.512161856889724\n",
            "Chain 2: L_m = 3.2913641899824144\n",
            "Chain 3: L_m = 3.9946631610393526\n",
            "Chain 4: L_m = 1.3746885716915132\n",
            "Chain 5: L_m = 1.413570660352707\n",
            "Chain 6: L_m = 3.412365901470184\n",
            "Chain 7: L_m = 2.0339708983898164\n",
            "Chain 8: L_m = 0.691975599527359\n",
            "Chain 9: L_m = 0.4212522566318512\n",
            "Chain 10: L_m = 0.9782685846090317\n",
            "Chain 11: L_m = 5.244519692659378\n",
            "Chain 12: L_m = 3.306220281124115\n",
            "Chain 13: L_m = 1.7976462692022324\n",
            "Chain 14: L_m = 2.0055090337991714\n",
            "Chain 15: L_m = 0.9875315964221955\n",
            "Chain 16: L_m = 2.908234643936157\n",
            "Chain 17: L_m = 2.026265561580658\n",
            "Chain 18: L_m = 1.5316135466098786\n",
            "Chain 19: L_m = 0.5079347610473632\n",
            "Chain 20: L_m = 2.1143519312143324\n",
            "Chain 21: L_m = 2.898058557510376\n",
            "Chain 22: L_m = 0.7913927376270294\n",
            "Chain 23: L_m = 2.5729620933532713\n",
            "Chain 24: L_m = 1.6496045470237732\n",
            "Chain 25: L_m = 5.118790417909622\n",
            "Chain 26: L_m = 0.7938552618026733\n",
            "Chain 27: L_m = 1.6792375564575195\n",
            "Chain 28: L_m = 0.4000787615776062\n",
            "Chain 29: L_m = 4.949735134840012\n",
            "Chain 30: L_m = 3.706572192907333\n",
            "Chain 31: L_m = 1.6227190881967544\n",
            "Chain 32: L_m = 3.4896310806274413\n",
            "Chain 33: L_m = 4.327707523107529\n",
            "Chain 34: L_m = 1.973887175321579\n",
            "Chain 35: L_m = 3.4051764607429504\n",
            "Chain 36: L_m = 3.3022558987140656\n",
            "Chain 37: L_m = 1.4940471678972245\n",
            "Chain 38: L_m = 0.5629656136035919\n",
            "Chain 39: L_m = 2.6381746172904967\n",
            "Chain 40: L_m = 2.6074885606765745\n",
            "Chain 41: L_m = 4.654715186357498\n",
            "Chain 42: L_m = 4.835841736197471\n",
            "Chain 43: L_m = 3.9649544060230255\n",
            "Chain 44: L_m = 0.4027536243200302\n",
            "Chain 45: L_m = 6.56050768494606\n",
            "Chain 46: L_m = 4.6166390657424925\n",
            "Chain 47: L_m = 1.3085197806358337\n",
            "Chain 48: L_m = 1.1465480774641037\n",
            "Chain 49: L_m = 0.7873665273189545\n",
            "Chain 50: L_m = 1.0797146052122115\n",
            "Chain 51: L_m = 5.149557048082352\n",
            "Chain 52: L_m = 1.6801091074943542\n",
            "Chain 53: L_m = 4.853229993581772\n",
            "Chain 54: L_m = 2.661680260300636\n",
            "Chain 55: L_m = 4.9192726612091064\n",
            "Chain 56: L_m = 2.591007897257805\n",
            "Chain 57: L_m = 1.1581324219703675\n",
            "Chain 58: L_m = 1.36450152695179\n",
            "Chain 59: L_m = 3.039877200126648\n",
            "Chain 60: L_m = 2.939451810717583\n",
            "Chain 61: L_m = 1.9868403732776643\n",
            "Chain 62: L_m = 3.125880962610245\n",
            "Chain 63: L_m = 3.599403178691864\n",
            "Chain 64: L_m = 2.6305473923683165\n",
            "Chain 65: L_m = 2.4524356842041017\n",
            "Chain 66: L_m = 3.9377553343772886\n",
            "Chain 67: L_m = 0.6372242659330368\n",
            "Chain 68: L_m = 3.3743065893650055\n",
            "Chain 69: L_m = 3.726719117164612\n",
            "Chain 70: L_m = 1.7387944430112838\n",
            "Chain 71: L_m = 5.1810880362987515\n",
            "Chain 72: L_m = 4.063623303174973\n",
            "Chain 73: L_m = 4.1668616235256195\n",
            "Chain 74: L_m = 1.5877668589353562\n",
            "Chain 75: L_m = 2.1849516689777375\n",
            "Chain 76: L_m = 1.0788323611021042\n",
            "Chain 77: L_m = 8.085529696941375\n",
            "Chain 78: L_m = 0.5532563760876655\n",
            "Chain 79: L_m = 1.6761222004890441\n",
            "Chain 80: L_m = 6.48221743106842\n",
            "Chain 81: L_m = 4.019860553741455\n",
            "Chain 82: L_m = 6.489056348800659\n",
            "Chain 83: L_m = 1.9389065980911255\n",
            "Chain 84: L_m = 5.747870087623596\n",
            "Chain 85: L_m = 5.8118631601333615\n",
            "Chain 86: L_m = 0.3056261122226715\n",
            "Chain 87: L_m = 1.8295481145381927\n",
            "Chain 88: L_m = 3.485871231555939\n",
            "Chain 89: L_m = 2.9121276527643203\n",
            "Chain 90: L_m = 1.5921040505170823\n",
            "Chain 91: L_m = 4.611672365665436\n",
            "Chain 92: L_m = 3.9065507113933564\n",
            "Chain 93: L_m = 0.8677286505699158\n",
            "Chain 94: L_m = 4.606375235319137\n",
            "Chain 95: L_m = 1.2219839215278625\n",
            "Chain 96: L_m = 4.756380689144135\n",
            "Chain 97: L_m = 0.7922168672084808\n",
            "Chain 98: L_m = 4.228265732526779\n",
            "Chain 99: L_m = 3.0539785981178285\n",
            "Chain 100: L_m = 3.959312927722931\n",
            "Chain 101: L_m = 0.32708812654018404\n",
            "Chain 102: L_m = 1.8721912920475006\n",
            "Chain 103: L_m = 4.994946014881134\n",
            "Chain 104: L_m = 5.849810263514518\n",
            "Chain 105: L_m = 3.032660073041916\n",
            "Chain 106: L_m = 5.12980740070343\n",
            "Chain 107: L_m = 0.7058861315250397\n",
            "Chain 108: L_m = 1.8750930190086366\n",
            "Chain 109: L_m = 3.82665678858757\n",
            "Chain 110: L_m = 7.150110656023026\n",
            "Chain 111: L_m = 2.1536423027515412\n",
            "Chain 112: L_m = 0.47479288578033446\n",
            "Chain 113: L_m = 3.6063053399324416\n",
            "Chain 114: L_m = 2.5103269428014756\n",
            "Chain 115: L_m = 2.7686768174171448\n",
            "Chain 116: L_m = 6.197839385271072\n",
            "Chain 117: L_m = 5.485598173737526\n",
            "Chain 118: L_m = 5.140778642892838\n",
            "Chain 119: L_m = 6.052863115072251\n",
            "Chain 120: L_m = 0.3683072030544281\n",
            "Chain 121: L_m = 1.0980685949325562\n",
            "Chain 122: L_m = 5.618709301948547\n",
            "Chain 123: L_m = 2.9040185272693635\n",
            "Chain 124: L_m = 1.0684163302183152\n",
            "Chain 125: L_m = 3.9122858941555023\n",
            "Chain 126: L_m = 1.1484551072120666\n",
            "Chain 127: L_m = 2.727912136912346\n",
            "Chain 128: L_m = 3.102934694290161\n",
            "Chain 129: L_m = 2.163059240579605\n",
            "Chain 130: L_m = 9.801942011713981\n",
            "Chain 131: L_m = 6.170450073480606\n",
            "Chain 132: L_m = 5.039105921983719\n",
            "Chain 133: L_m = 0.82653848528862\n",
            "Chain 134: L_m = 0.711678272485733\n",
            "Chain 135: L_m = 2.6951353907585145\n",
            "Chain 136: L_m = 3.664037024974823\n",
            "Chain 137: L_m = 6.3892236173152925\n",
            "Chain 138: L_m = 5.470403730869293\n",
            "Chain 139: L_m = 3.566566076874733\n",
            "Chain 140: L_m = 2.441759783029556\n",
            "Chain 141: L_m = 0.8179157376289368\n",
            "Chain 142: L_m = 4.7022818386554714\n",
            "Chain 143: L_m = 1.5218682646751405\n",
            "Chain 144: L_m = 4.734474596381188\n",
            "Chain 145: L_m = 2.728882706165314\n",
            "Chain 146: L_m = 4.146179431676865\n",
            "Chain 147: L_m = 0.9579567790031434\n",
            "Chain 148: L_m = 0.7391070812940598\n",
            "Chain 149: L_m = 1.8182167053222655\n",
            "Chain 150: L_m = 4.219857412576675\n",
            "Chain 151: L_m = 7.279444438219071\n",
            "Chain 152: L_m = 0.44369879364967346\n",
            "Chain 153: L_m = 2.392556345462799\n",
            "Chain 154: L_m = 1.9990143477916718\n",
            "Chain 155: L_m = 4.267237442731857\n",
            "Chain 156: L_m = 3.195277673006058\n",
            "Chain 157: L_m = 4.555492186546326\n",
            "Chain 158: L_m = 3.7066943854093553\n",
            "Chain 159: L_m = 3.3641305327415467\n",
            "Chain 160: L_m = 2.039209881424904\n",
            "Chain 161: L_m = 3.3516682982444763\n",
            "Chain 162: L_m = 3.273442932963371\n",
            "Chain 163: L_m = 1.3411988466978073\n",
            "Chain 164: L_m = 2.437044197320938\n",
            "Chain 165: L_m = 5.200130376219749\n",
            "Chain 166: L_m = 1.7691589891910553\n",
            "Chain 167: L_m = 1.3905838012695313\n",
            "Chain 168: L_m = 1.1584915488958358\n",
            "Chain 169: L_m = 1.0755758613348008\n",
            "Chain 170: L_m = 3.051571625471115\n",
            "Chain 171: L_m = 1.8213535040616988\n",
            "Chain 172: L_m = 5.170852786302566\n",
            "Chain 173: L_m = 1.7392124593257905\n",
            "Chain 174: L_m = 0.3341030806303024\n",
            "Chain 175: L_m = 4.6644132256507875\n",
            "Chain 176: L_m = 3.902470400929451\n",
            "Chain 177: L_m = 8.01248566508293\n",
            "Chain 178: L_m = 1.2405304908752441\n",
            "Chain 179: L_m = 5.530807688832283\n",
            "Chain 180: L_m = 6.555142623186112\n",
            "Chain 181: L_m = 1.8601514101028442\n",
            "Chain 182: L_m = 0.4279170721769333\n",
            "Chain 183: L_m = 5.38589970767498\n",
            "Chain 184: L_m = 5.260770690441132\n",
            "Chain 185: L_m = 1.209993663430214\n",
            "Chain 186: L_m = 1.2547966241836548\n",
            "Chain 187: L_m = 5.159635245800018\n",
            "Chain 188: L_m = 1.372859963774681\n",
            "Chain 189: L_m = 2.2736343324184416\n",
            "Chain 190: L_m = 4.025007173418999\n",
            "Chain 191: L_m = 0.636082011461258\n",
            "Chain 192: L_m = 6.2829402655363085\n",
            "Chain 193: L_m = 2.4454558551311494\n",
            "Chain 194: L_m = 2.9131862342357637\n",
            "Chain 195: L_m = 1.476769471168518\n",
            "Chain 196: L_m = 2.753788286447525\n",
            "Chain 197: L_m = 3.5687802970409392\n",
            "Chain 198: L_m = 2.9535664677619935\n",
            "Chain 199: L_m = 1.75959911942482\n",
            "Chain 200: L_m = 0.8185251832008362\n",
            "LFE: 269.64k (std: 167.68k, n_chain=200)\n",
            "\n",
            "---\n",
            "Data for model 4:\n",
            "95% lambdahat confidence interval: 19.23k-23.39k\n",
            "Mean lambdahat: 21.31k\n",
            "Free energy: 269.64k\n",
            "Energy: 26.54k\n",
            "---\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chain 1: L_m = 1.7143892109394074\n",
            "Chain 2: L_m = 1.6269792318344116\n",
            "Chain 3: L_m = 0.21123700886964797\n",
            "Chain 4: L_m = 0.44388504326343536\n",
            "Chain 5: L_m = 0.3481792688369751\n",
            "Chain 6: L_m = 1.2627573311328888\n",
            "Chain 7: L_m = 0.3580059617757797\n",
            "Chain 8: L_m = 1.4979170203208922\n",
            "Chain 9: L_m = 0.9597122550010682\n",
            "Chain 10: L_m = 1.094135332107544\n",
            "Chain 11: L_m = 1.0743216514587401\n",
            "Chain 12: L_m = 1.7775719463825226\n",
            "Chain 13: L_m = 1.929034447669983\n",
            "Chain 14: L_m = 0.9286267161369324\n",
            "Chain 15: L_m = 1.4787593007087707\n",
            "Chain 16: L_m = 0.23279042541980743\n",
            "Chain 17: L_m = 1.043607661128044\n",
            "Chain 18: L_m = 0.38135826587677\n",
            "Chain 19: L_m = 0.6841808587312699\n",
            "Chain 20: L_m = 0.8642332136631012\n",
            "Chain 21: L_m = 1.4391672253608703\n",
            "Chain 22: L_m = 1.899801766872406\n",
            "Chain 23: L_m = 1.5323917806148528\n",
            "Chain 24: L_m = 1.4584864318370818\n",
            "Chain 25: L_m = 1.5233963966369628\n",
            "Chain 26: L_m = 0.47550772726535795\n",
            "Chain 27: L_m = 1.687919980287552\n",
            "Chain 28: L_m = 0.31120317578315737\n",
            "Chain 29: L_m = 0.9499550700187683\n",
            "Chain 30: L_m = 0.31927003562450407\n",
            "Chain 31: L_m = 0.39984922409057616\n",
            "Chain 32: L_m = 1.4127140045166016\n",
            "Chain 33: L_m = 1.5218278110027312\n",
            "Chain 34: L_m = 1.5591455101966858\n",
            "Chain 35: L_m = 1.2906995475292207\n",
            "Chain 36: L_m = 1.124248605966568\n",
            "Chain 37: L_m = 1.099045729637146\n",
            "Chain 38: L_m = 1.5585671424865724\n",
            "Chain 39: L_m = 0.4993420511484146\n",
            "Chain 40: L_m = 0.6274206548929214\n",
            "Chain 41: L_m = 1.0099882692098618\n",
            "Chain 42: L_m = 1.23437140583992\n",
            "Chain 43: L_m = 1.2384789526462554\n",
            "Chain 44: L_m = 1.6333246290683747\n",
            "Chain 45: L_m = 1.5594971776008606\n",
            "Chain 46: L_m = 0.6071384936571121\n",
            "Chain 47: L_m = 0.5166226685047149\n",
            "Chain 48: L_m = 1.2659727454185485\n",
            "Chain 49: L_m = 1.1209365665912627\n",
            "Chain 50: L_m = 0.2942466527223587\n",
            "Chain 51: L_m = 0.9784781903028488\n",
            "Chain 52: L_m = 1.2723787128925323\n",
            "Chain 53: L_m = 0.6158794283866882\n",
            "Chain 54: L_m = 1.4659115016460418\n",
            "Chain 55: L_m = 1.5074097275733949\n",
            "Chain 56: L_m = 0.9886135622859001\n",
            "Chain 57: L_m = 1.535146802663803\n",
            "Chain 58: L_m = 1.6417902648448943\n",
            "Chain 59: L_m = 1.038580721616745\n",
            "Chain 60: L_m = 1.3310608446598053\n",
            "Chain 61: L_m = 0.9059137403964996\n",
            "Chain 62: L_m = 0.9387630105018616\n",
            "Chain 63: L_m = 1.1282666236162187\n",
            "Chain 64: L_m = 2.386180502176285\n",
            "Chain 65: L_m = 0.8642726719379425\n",
            "Chain 66: L_m = 0.24107597172260284\n",
            "Chain 67: L_m = 1.2536028683185578\n",
            "Chain 68: L_m = 1.3891778945922852\n",
            "Chain 69: L_m = 1.2192656874656678\n",
            "Chain 70: L_m = 1.4900075972080231\n",
            "Chain 71: L_m = 1.4386794328689576\n",
            "Chain 72: L_m = 0.45734378397464753\n",
            "Chain 73: L_m = 0.827927577495575\n",
            "Chain 74: L_m = 0.2797572761774063\n",
            "Chain 75: L_m = 1.2920846223831177\n",
            "Chain 76: L_m = 1.1294535577297211\n",
            "Chain 77: L_m = 0.9335586607456208\n",
            "Chain 78: L_m = 0.571484524011612\n",
            "Chain 79: L_m = 1.2438661217689515\n",
            "Chain 80: L_m = 0.9164068281650544\n",
            "Chain 81: L_m = 0.7270843505859375\n",
            "Chain 82: L_m = 1.1041438579559326\n",
            "Chain 83: L_m = 1.515815442800522\n",
            "Chain 84: L_m = 0.8861065208911896\n",
            "Chain 85: L_m = 1.0229816913604737\n",
            "Chain 86: L_m = 0.5991275131702423\n",
            "Chain 87: L_m = 0.3908611863851547\n",
            "Chain 88: L_m = 1.6109712660312652\n",
            "Chain 89: L_m = 1.0317495539784431\n",
            "Chain 90: L_m = 1.7001776158809663\n",
            "Chain 91: L_m = 0.891743290424347\n",
            "Chain 92: L_m = 1.4473999857902526\n",
            "Chain 93: L_m = 1.0058230578899383\n",
            "Chain 94: L_m = 1.5917960464954377\n",
            "Chain 95: L_m = 0.42332836985588074\n",
            "Chain 96: L_m = 1.0860868990421295\n",
            "Chain 97: L_m = 1.1721826672554017\n",
            "Chain 98: L_m = 1.3626580283045768\n",
            "Chain 99: L_m = 1.6867904961109161\n",
            "Chain 100: L_m = 1.2173732280731202\n",
            "Chain 101: L_m = 1.2517010986804962\n",
            "Chain 102: L_m = 1.2553340375423432\n",
            "Chain 103: L_m = 1.4365529596805573\n",
            "Chain 104: L_m = 1.461400842666626\n",
            "Chain 105: L_m = 0.2380944460630417\n",
            "Chain 106: L_m = 1.0541833877563476\n",
            "Chain 107: L_m = 1.1323917925357818\n",
            "Chain 108: L_m = 1.424947828054428\n",
            "Chain 109: L_m = 1.9344456672668457\n",
            "Chain 110: L_m = 0.6794113218784332\n",
            "Chain 111: L_m = 1.1903044044971467\n",
            "Chain 112: L_m = 0.9860154330730438\n",
            "Chain 113: L_m = 1.988972109556198\n",
            "Chain 114: L_m = 1.4539025664329528\n",
            "Chain 115: L_m = 1.3783579409122466\n",
            "Chain 116: L_m = 1.0532548308372498\n",
            "Chain 117: L_m = 1.7750980257987976\n",
            "Chain 118: L_m = 1.6753419995307923\n",
            "Chain 119: L_m = 0.7197538077831268\n",
            "Chain 120: L_m = 1.86764098405838\n",
            "Chain 121: L_m = 0.3461636781692505\n",
            "Chain 122: L_m = 0.43601214289665224\n",
            "Chain 123: L_m = 1.2078110456466675\n",
            "Chain 124: L_m = 0.6957690298557282\n",
            "Chain 125: L_m = 1.3398586869239808\n",
            "Chain 126: L_m = 0.7538812458515167\n",
            "Chain 127: L_m = 1.374576783180237\n",
            "Chain 128: L_m = 1.4371931314468385\n",
            "Chain 129: L_m = 1.0286408543586731\n",
            "Chain 130: L_m = 1.7213141828775407\n",
            "Chain 131: L_m = 0.3906200885772705\n",
            "Chain 132: L_m = 1.3337416112422944\n",
            "Chain 133: L_m = 1.1179804503917694\n",
            "Chain 134: L_m = 0.8829747498035431\n",
            "Chain 135: L_m = 1.5700232565402985\n",
            "Chain 136: L_m = 1.1900441139936446\n",
            "Chain 137: L_m = 1.1500576734542847\n",
            "Chain 138: L_m = 1.5351141035556792\n",
            "Chain 139: L_m = 1.5131486982107163\n",
            "Chain 140: L_m = 0.3699961811304092\n",
            "Chain 141: L_m = 0.45251700580120086\n",
            "Chain 142: L_m = 0.6712301731109619\n",
            "Chain 143: L_m = 0.5837986588478088\n",
            "Chain 144: L_m = 1.5059452533721924\n",
            "Chain 145: L_m = 0.647645714879036\n",
            "Chain 146: L_m = 1.986019992828369\n",
            "Chain 147: L_m = 1.014410489797592\n",
            "Chain 148: L_m = 0.555307286977768\n",
            "Chain 149: L_m = 0.9029529213905334\n",
            "Chain 150: L_m = 1.0698410451412201\n",
            "Chain 151: L_m = 2.126622959971428\n",
            "Chain 152: L_m = 1.5902728319168091\n",
            "Chain 153: L_m = 2.0643765807151793\n",
            "Chain 154: L_m = 0.7836461126804352\n",
            "Chain 155: L_m = 0.9783841907978058\n",
            "Chain 156: L_m = 0.2928493320941925\n",
            "Chain 157: L_m = 1.3110038757324218\n",
            "Chain 158: L_m = 0.873809278011322\n",
            "Chain 159: L_m = 1.1247121423482895\n",
            "Chain 160: L_m = 1.1315677255392074\n",
            "Chain 161: L_m = 1.0402765989303588\n",
            "Chain 162: L_m = 1.2800589501857758\n",
            "Chain 163: L_m = 1.264375388622284\n",
            "Chain 164: L_m = 0.8291560053825379\n",
            "Chain 165: L_m = 1.3479025959968567\n",
            "Chain 166: L_m = 1.152709847688675\n",
            "Chain 167: L_m = 0.7468128561973572\n",
            "Chain 168: L_m = 0.9276036620140076\n",
            "Chain 169: L_m = 1.1674885272979736\n",
            "Chain 170: L_m = 1.0162033498287202\n",
            "Chain 171: L_m = 1.4729918509721756\n",
            "Chain 172: L_m = 1.1196524620056152\n",
            "Chain 173: L_m = 0.3701928973197937\n",
            "Chain 174: L_m = 1.0073616743087768\n",
            "Chain 175: L_m = 1.8036558866500854\n",
            "Chain 176: L_m = 0.9215295046567917\n",
            "Chain 177: L_m = 1.192706298828125\n",
            "Chain 178: L_m = 0.29541071951389314\n",
            "Chain 179: L_m = 1.017826896905899\n",
            "Chain 180: L_m = 0.7461108922958374\n",
            "Chain 181: L_m = 1.1363844603300095\n",
            "Chain 182: L_m = 0.5367986112833023\n",
            "Chain 183: L_m = 1.1850834488868713\n",
            "Chain 184: L_m = 0.7688974529504776\n",
            "Chain 185: L_m = 1.2341166615486145\n",
            "Chain 186: L_m = 1.6215007483959198\n",
            "Chain 187: L_m = 1.0670977383852005\n",
            "Chain 188: L_m = 0.3496124595403671\n",
            "Chain 189: L_m = 0.8008069276809693\n",
            "Chain 190: L_m = 0.7181091666221618\n",
            "Chain 191: L_m = 1.0884973168373109\n",
            "Chain 192: L_m = 1.9865215599536896\n",
            "Chain 193: L_m = 1.0835969358682633\n",
            "Chain 194: L_m = 1.7320557832717896\n",
            "Chain 195: L_m = 1.2051424086093903\n",
            "Chain 196: L_m = 2.5309659957885744\n",
            "Chain 197: L_m = 1.0404913008213044\n",
            "Chain 198: L_m = 1.3136215269565583\n",
            "Chain 199: L_m = 0.7909691095352173\n",
            "Chain 200: L_m = 0.812995833158493\n",
            "LFE: 99.71k (std: 41.50k, n_chain=200)\n",
            "\n",
            "---\n",
            "Data for model 4:\n",
            "95% lambdahat confidence interval: 5.82k-6.85k\n",
            "Mean lambdahat: 6.33k\n",
            "Free energy: 99.71k\n",
            "Energy: 27.45k\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(model_rlct_mid)):\n",
        "  print(f\"Model {i+1}:\")\n",
        "  print(f\"95% lambda hat CI: {EngNumber(model_rlct_low[i])} - {EngNumber(model_rlct_high[i])}\")\n",
        "  print(f\"Mean lambda hat: {EngNumber(model_rlct_mid[i])}\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "ZvxLaixwfzAF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac32eb70-ad36-42d9-b3d0-a9cf4ffcb0af"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 1:\n",
            "95% lambda hat CI: 2.76k - 3.59k\n",
            "Mean lambda hat: 3.17k\n",
            "\n",
            "Model 2:\n",
            "95% lambda hat CI: 14.57k - 18.31k\n",
            "Mean lambda hat: 16.44k\n",
            "\n",
            "Model 3:\n",
            "95% lambda hat CI: 4.55k - 5.59k\n",
            "Mean lambda hat: 5.07k\n",
            "\n",
            "Model 4:\n",
            "95% lambda hat CI: 19.23k - 23.39k\n",
            "Mean lambda hat: 21.31k\n",
            "\n",
            "Model 5:\n",
            "95% lambda hat CI: 5.82k - 6.85k\n",
            "Mean lambda hat: 6.33k\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nlU6g2eudO9O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}